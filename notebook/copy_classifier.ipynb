{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dataset_path='../data/raw/UrbanSound8K/audio/'\n",
    "metadata=pd.read_csv(f'../data/raw/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3554it [03:22, 18.36it/s]c:\\Users\\felip\\OneDrive\\Documentos\\_Maua\\tcc\\ml_tcc\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  return f(*args, **kwargs)\n",
      "8325it [07:35, 27.10it/s]c:\\Users\\felip\\OneDrive\\Documentos\\_Maua\\tcc\\ml_tcc\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\felip\\OneDrive\\Documentos\\_Maua\\tcc\\ml_tcc\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  return f(*args, **kwargs)\n",
      "8732it [07:54, 18.42it/s]\n"
     ]
    }
   ],
   "source": [
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-217.35526, 70.22338, -130.38527, -53.282898,...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-424.09818, 109.34077, -52.919525, 60.86475, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-458.79114, 121.38419, -46.52066, 52.00812, -...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-413.89984, 101.66373, -35.42945, 53.036354, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-446.60352, 113.68541, -52.402214, 60.302044,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature             class\n",
       "0  [-217.35526, 70.22338, -130.38527, -53.282898,...          dog_bark\n",
       "1  [-424.09818, 109.34077, -52.919525, 60.86475, ...  children_playing\n",
       "2  [-458.79114, 121.38419, -46.52066, 52.00812, -...  children_playing\n",
       "3  [-413.89984, 101.66373, -35.42945, 53.036354, ...  children_playing\n",
       "4  [-446.60352, 113.68541, -52.402214, 60.302044,...  children_playing"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dog_bark', 'children_playing', 'children_playing', ...,\n",
       "       'car_horn', 'car_horn', 'car_horn'], dtype='<U16')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding\n",
    "###y=np.array(pd.get_dummies(y))\n",
    "### Label Encoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,410\n",
      "Trainable params: 45,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 9.5601 - accuracy: 0.1290 \n",
      "Epoch 1: val_loss improved from inf to 2.28622, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 8.8166 - accuracy: 0.1298 - val_loss: 2.2862 - val_accuracy: 0.1013\n",
      "Epoch 2/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 2.4813 - accuracy: 0.1261\n",
      "Epoch 2: val_loss improved from 2.28622 to 2.25073, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 2.4687 - accuracy: 0.1270 - val_loss: 2.2507 - val_accuracy: 0.0973\n",
      "Epoch 3/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 2.2945 - accuracy: 0.1427\n",
      "Epoch 3: val_loss improved from 2.25073 to 2.17417, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 2.2948 - accuracy: 0.1442 - val_loss: 2.1742 - val_accuracy: 0.1729\n",
      "Epoch 4/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 2.2143 - accuracy: 0.1754\n",
      "Epoch 4: val_loss improved from 2.17417 to 2.13071, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 2.2124 - accuracy: 0.1752 - val_loss: 2.1307 - val_accuracy: 0.2032\n",
      "Epoch 5/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 2.1791 - accuracy: 0.1882\n",
      "Epoch 5: val_loss improved from 2.13071 to 2.06466, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 2.1793 - accuracy: 0.1884 - val_loss: 2.0647 - val_accuracy: 0.2318\n",
      "Epoch 6/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 2.1381 - accuracy: 0.1972\n",
      "Epoch 6: val_loss improved from 2.06466 to 2.05481, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 2.1380 - accuracy: 0.1977 - val_loss: 2.0548 - val_accuracy: 0.2330\n",
      "Epoch 7/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 2.0994 - accuracy: 0.2141\n",
      "Epoch 7: val_loss improved from 2.05481 to 1.99745, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 2.0987 - accuracy: 0.2150 - val_loss: 1.9975 - val_accuracy: 0.2942\n",
      "Epoch 8/100\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 2.0270 - accuracy: 0.2324\n",
      "Epoch 8: val_loss improved from 1.99745 to 1.93283, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 2.0331 - accuracy: 0.2305 - val_loss: 1.9328 - val_accuracy: 0.2742\n",
      "Epoch 9/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 1.9858 - accuracy: 0.2602\n",
      "Epoch 9: val_loss improved from 1.93283 to 1.83475, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.9866 - accuracy: 0.2593 - val_loss: 1.8348 - val_accuracy: 0.3784\n",
      "Epoch 10/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.9833 - accuracy: 0.2838\n",
      "Epoch 10: val_loss improved from 1.83475 to 1.80600, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.9787 - accuracy: 0.2826 - val_loss: 1.8060 - val_accuracy: 0.3778\n",
      "Epoch 11/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.9212 - accuracy: 0.3095\n",
      "Epoch 11: val_loss improved from 1.80600 to 1.73437, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.9200 - accuracy: 0.3094 - val_loss: 1.7344 - val_accuracy: 0.4219\n",
      "Epoch 12/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 1.8941 - accuracy: 0.3222\n",
      "Epoch 12: val_loss improved from 1.73437 to 1.71514, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.8954 - accuracy: 0.3221 - val_loss: 1.7151 - val_accuracy: 0.4219\n",
      "Epoch 13/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 1.8478 - accuracy: 0.3395\n",
      "Epoch 13: val_loss improved from 1.71514 to 1.64617, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.8452 - accuracy: 0.3416 - val_loss: 1.6462 - val_accuracy: 0.4568\n",
      "Epoch 14/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 1.8341 - accuracy: 0.3503\n",
      "Epoch 14: val_loss improved from 1.64617 to 1.60298, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.8299 - accuracy: 0.3509 - val_loss: 1.6030 - val_accuracy: 0.4516\n",
      "Epoch 15/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 1.7658 - accuracy: 0.3650\n",
      "Epoch 15: val_loss improved from 1.60298 to 1.58755, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.7684 - accuracy: 0.3654 - val_loss: 1.5875 - val_accuracy: 0.4539\n",
      "Epoch 16/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.7358 - accuracy: 0.3908\n",
      "Epoch 16: val_loss improved from 1.58755 to 1.55161, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.7366 - accuracy: 0.3898 - val_loss: 1.5516 - val_accuracy: 0.4762\n",
      "Epoch 17/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 1.6876 - accuracy: 0.4025\n",
      "Epoch 17: val_loss improved from 1.55161 to 1.50862, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.6925 - accuracy: 0.4021 - val_loss: 1.5086 - val_accuracy: 0.5060\n",
      "Epoch 18/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.6728 - accuracy: 0.4075\n",
      "Epoch 18: val_loss improved from 1.50862 to 1.43973, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.6689 - accuracy: 0.4099 - val_loss: 1.4397 - val_accuracy: 0.5266\n",
      "Epoch 19/100\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 1.6211 - accuracy: 0.4308\n",
      "Epoch 19: val_loss improved from 1.43973 to 1.36386, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.6135 - accuracy: 0.4305 - val_loss: 1.3639 - val_accuracy: 0.5661\n",
      "Epoch 20/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.5911 - accuracy: 0.4448\n",
      "Epoch 20: val_loss improved from 1.36386 to 1.31618, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.5919 - accuracy: 0.4465 - val_loss: 1.3162 - val_accuracy: 0.5758\n",
      "Epoch 21/100\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 1.5773 - accuracy: 0.4502\n",
      "Epoch 21: val_loss improved from 1.31618 to 1.29584, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.5756 - accuracy: 0.4494 - val_loss: 1.2958 - val_accuracy: 0.5816\n",
      "Epoch 22/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 1.5455 - accuracy: 0.4547\n",
      "Epoch 22: val_loss did not improve from 1.29584\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.5431 - accuracy: 0.4547 - val_loss: 1.3180 - val_accuracy: 0.5661\n",
      "Epoch 23/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.4857 - accuracy: 0.4763\n",
      "Epoch 23: val_loss improved from 1.29584 to 1.29132, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.4880 - accuracy: 0.4786 - val_loss: 1.2913 - val_accuracy: 0.5667\n",
      "Epoch 24/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.4767 - accuracy: 0.4899\n",
      "Epoch 24: val_loss improved from 1.29132 to 1.21834, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.4797 - accuracy: 0.4893 - val_loss: 1.2183 - val_accuracy: 0.6079\n",
      "Epoch 25/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.4628 - accuracy: 0.4934\n",
      "Epoch 25: val_loss improved from 1.21834 to 1.20819, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.4615 - accuracy: 0.4941 - val_loss: 1.2082 - val_accuracy: 0.6199\n",
      "Epoch 26/100\n",
      "192/219 [=========================>....] - ETA: 0s - loss: 1.4258 - accuracy: 0.5094\n",
      "Epoch 26: val_loss improved from 1.20819 to 1.18872, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.4293 - accuracy: 0.5091 - val_loss: 1.1887 - val_accuracy: 0.6182\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.3976 - accuracy: 0.5241\n",
      "Epoch 27: val_loss did not improve from 1.18872\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.3976 - accuracy: 0.5241 - val_loss: 1.2110 - val_accuracy: 0.6056\n",
      "Epoch 28/100\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 1.4019 - accuracy: 0.5181\n",
      "Epoch 28: val_loss improved from 1.18872 to 1.16998, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.4005 - accuracy: 0.5193 - val_loss: 1.1700 - val_accuracy: 0.6234\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.3754 - accuracy: 0.5243\n",
      "Epoch 29: val_loss did not improve from 1.16998\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.3754 - accuracy: 0.5243 - val_loss: 1.1704 - val_accuracy: 0.6142\n",
      "Epoch 30/100\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 1.3585 - accuracy: 0.5356\n",
      "Epoch 30: val_loss improved from 1.16998 to 1.13369, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.3614 - accuracy: 0.5346 - val_loss: 1.1337 - val_accuracy: 0.6382\n",
      "Epoch 31/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.3280 - accuracy: 0.5424\n",
      "Epoch 31: val_loss improved from 1.13369 to 1.10784, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.3372 - accuracy: 0.5412 - val_loss: 1.1078 - val_accuracy: 0.6422\n",
      "Epoch 32/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 1.3282 - accuracy: 0.5430\n",
      "Epoch 32: val_loss did not improve from 1.10784\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.3343 - accuracy: 0.5414 - val_loss: 1.1443 - val_accuracy: 0.6405\n",
      "Epoch 33/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.3262 - accuracy: 0.5550\n",
      "Epoch 33: val_loss improved from 1.10784 to 1.08879, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.3287 - accuracy: 0.5542 - val_loss: 1.0888 - val_accuracy: 0.6566\n",
      "Epoch 34/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 1.3029 - accuracy: 0.5567\n",
      "Epoch 34: val_loss improved from 1.08879 to 1.07773, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.3019 - accuracy: 0.5563 - val_loss: 1.0777 - val_accuracy: 0.6703\n",
      "Epoch 35/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.2632 - accuracy: 0.5628\n",
      "Epoch 35: val_loss improved from 1.07773 to 1.05049, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.2639 - accuracy: 0.5648 - val_loss: 1.0505 - val_accuracy: 0.6646\n",
      "Epoch 36/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.2705 - accuracy: 0.5686\n",
      "Epoch 36: val_loss did not improve from 1.05049\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.2640 - accuracy: 0.5681 - val_loss: 1.0716 - val_accuracy: 0.6640\n",
      "Epoch 37/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 1.2566 - accuracy: 0.5830\n",
      "Epoch 37: val_loss improved from 1.05049 to 1.04862, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.2603 - accuracy: 0.5807 - val_loss: 1.0486 - val_accuracy: 0.6623\n",
      "Epoch 38/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.2654 - accuracy: 0.5784\n",
      "Epoch 38: val_loss improved from 1.04862 to 1.03623, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.2606 - accuracy: 0.5795 - val_loss: 1.0362 - val_accuracy: 0.6795\n",
      "Epoch 39/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.2234 - accuracy: 0.5921\n",
      "Epoch 39: val_loss improved from 1.03623 to 1.02861, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.2187 - accuracy: 0.5913 - val_loss: 1.0286 - val_accuracy: 0.6669\n",
      "Epoch 40/100\n",
      "193/219 [=========================>....] - ETA: 0s - loss: 1.2206 - accuracy: 0.5889\n",
      "Epoch 40: val_loss improved from 1.02861 to 1.00327, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.2251 - accuracy: 0.5871 - val_loss: 1.0033 - val_accuracy: 0.6852\n",
      "Epoch 41/100\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 1.2164 - accuracy: 0.5942\n",
      "Epoch 41: val_loss did not improve from 1.00327\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.2185 - accuracy: 0.5908 - val_loss: 1.0483 - val_accuracy: 0.6566\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.1928 - accuracy: 0.6007\n",
      "Epoch 42: val_loss did not improve from 1.00327\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1928 - accuracy: 0.6007 - val_loss: 1.0058 - val_accuracy: 0.6783\n",
      "Epoch 43/100\n",
      "193/219 [=========================>....] - ETA: 0s - loss: 1.1839 - accuracy: 0.6096\n",
      "Epoch 43: val_loss improved from 1.00327 to 0.99014, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1989 - accuracy: 0.6034 - val_loss: 0.9901 - val_accuracy: 0.6852\n",
      "Epoch 44/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 1.2136 - accuracy: 0.6034\n",
      "Epoch 44: val_loss improved from 0.99014 to 0.98297, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.2122 - accuracy: 0.6036 - val_loss: 0.9830 - val_accuracy: 0.6743\n",
      "Epoch 45/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.1860 - accuracy: 0.6075\n",
      "Epoch 45: val_loss did not improve from 0.98297\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1880 - accuracy: 0.6073 - val_loss: 1.0203 - val_accuracy: 0.6674\n",
      "Epoch 46/100\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 1.1720 - accuracy: 0.6092\n",
      "Epoch 46: val_loss improved from 0.98297 to 0.96587, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1724 - accuracy: 0.6074 - val_loss: 0.9659 - val_accuracy: 0.6817\n",
      "Epoch 47/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.1585 - accuracy: 0.6193\n",
      "Epoch 47: val_loss improved from 0.96587 to 0.94918, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1530 - accuracy: 0.6208 - val_loss: 0.9492 - val_accuracy: 0.6852\n",
      "Epoch 48/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 1.1538 - accuracy: 0.6176\n",
      "Epoch 48: val_loss did not improve from 0.94918\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1522 - accuracy: 0.6182 - val_loss: 0.9777 - val_accuracy: 0.6938\n",
      "Epoch 49/100\n",
      "193/219 [=========================>....] - ETA: 0s - loss: 1.1516 - accuracy: 0.6167\n",
      "Epoch 49: val_loss did not improve from 0.94918\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1507 - accuracy: 0.6176 - val_loss: 0.9564 - val_accuracy: 0.6983\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.1478 - accuracy: 0.6190\n",
      "Epoch 50: val_loss did not improve from 0.94918\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1478 - accuracy: 0.6190 - val_loss: 0.9654 - val_accuracy: 0.6978\n",
      "Epoch 51/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.1157 - accuracy: 0.6258\n",
      "Epoch 51: val_loss improved from 0.94918 to 0.93829, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1254 - accuracy: 0.6239 - val_loss: 0.9383 - val_accuracy: 0.7035\n",
      "Epoch 52/100\n",
      "191/219 [=========================>....] - ETA: 0s - loss: 1.1502 - accuracy: 0.6201\n",
      "Epoch 52: val_loss did not improve from 0.93829\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1507 - accuracy: 0.6188 - val_loss: 0.9392 - val_accuracy: 0.7035\n",
      "Epoch 53/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.1226 - accuracy: 0.6244\n",
      "Epoch 53: val_loss did not improve from 0.93829\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1246 - accuracy: 0.6266 - val_loss: 0.9481 - val_accuracy: 0.7121\n",
      "Epoch 54/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 1.1177 - accuracy: 0.6229\n",
      "Epoch 54: val_loss improved from 0.93829 to 0.92988, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1206 - accuracy: 0.6209 - val_loss: 0.9299 - val_accuracy: 0.7018\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.1068 - accuracy: 0.6225\n",
      "Epoch 55: val_loss did not improve from 0.92988\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1068 - accuracy: 0.6225 - val_loss: 0.9496 - val_accuracy: 0.6898\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.1006 - accuracy: 0.6282\n",
      "Epoch 56: val_loss improved from 0.92988 to 0.91354, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1006 - accuracy: 0.6282 - val_loss: 0.9135 - val_accuracy: 0.7138\n",
      "Epoch 57/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.1217 - accuracy: 0.6304\n",
      "Epoch 57: val_loss did not improve from 0.91354\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1120 - accuracy: 0.6344 - val_loss: 0.9301 - val_accuracy: 0.7046\n",
      "Epoch 58/100\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 1.1209 - accuracy: 0.6248\n",
      "Epoch 58: val_loss did not improve from 0.91354\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1192 - accuracy: 0.6266 - val_loss: 0.9380 - val_accuracy: 0.6995\n",
      "Epoch 59/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 1.0909 - accuracy: 0.6320\n",
      "Epoch 59: val_loss did not improve from 0.91354\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0862 - accuracy: 0.6336 - val_loss: 0.9370 - val_accuracy: 0.6932\n",
      "Epoch 60/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.0902 - accuracy: 0.6356\n",
      "Epoch 60: val_loss improved from 0.91354 to 0.91138, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0875 - accuracy: 0.6364 - val_loss: 0.9114 - val_accuracy: 0.7230\n",
      "Epoch 61/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 1.0779 - accuracy: 0.6390\n",
      "Epoch 61: val_loss did not improve from 0.91138\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0821 - accuracy: 0.6391 - val_loss: 0.9203 - val_accuracy: 0.7184\n",
      "Epoch 62/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 1.0965 - accuracy: 0.6313\n",
      "Epoch 62: val_loss did not improve from 0.91138\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0944 - accuracy: 0.6318 - val_loss: 0.9128 - val_accuracy: 0.7098\n",
      "Epoch 63/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 1.0807 - accuracy: 0.6412\n",
      "Epoch 63: val_loss improved from 0.91138 to 0.90701, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0865 - accuracy: 0.6389 - val_loss: 0.9070 - val_accuracy: 0.7189\n",
      "Epoch 64/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.0634 - accuracy: 0.6464\n",
      "Epoch 64: val_loss did not improve from 0.90701\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0604 - accuracy: 0.6474 - val_loss: 0.9082 - val_accuracy: 0.7218\n",
      "Epoch 65/100\n",
      "191/219 [=========================>....] - ETA: 0s - loss: 1.0854 - accuracy: 0.6415\n",
      "Epoch 65: val_loss improved from 0.90701 to 0.90511, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0829 - accuracy: 0.6429 - val_loss: 0.9051 - val_accuracy: 0.7104\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.0805 - accuracy: 0.6411\n",
      "Epoch 66: val_loss improved from 0.90511 to 0.89143, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0805 - accuracy: 0.6411 - val_loss: 0.8914 - val_accuracy: 0.7310\n",
      "Epoch 67/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.0679 - accuracy: 0.6443\n",
      "Epoch 67: val_loss improved from 0.89143 to 0.88330, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0600 - accuracy: 0.6464 - val_loss: 0.8833 - val_accuracy: 0.7327\n",
      "Epoch 68/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0749 - accuracy: 0.6441\n",
      "Epoch 68: val_loss did not improve from 0.88330\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0784 - accuracy: 0.6408 - val_loss: 0.8928 - val_accuracy: 0.7224\n",
      "Epoch 69/100\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 1.0616 - accuracy: 0.6508\n",
      "Epoch 69: val_loss did not improve from 0.88330\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0639 - accuracy: 0.6484 - val_loss: 0.8971 - val_accuracy: 0.7224\n",
      "Epoch 70/100\n",
      "191/219 [=========================>....] - ETA: 0s - loss: 1.0470 - accuracy: 0.6536\n",
      "Epoch 70: val_loss did not improve from 0.88330\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0510 - accuracy: 0.6547 - val_loss: 0.9093 - val_accuracy: 0.7241\n",
      "Epoch 71/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0436 - accuracy: 0.6555\n",
      "Epoch 71: val_loss did not improve from 0.88330\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0520 - accuracy: 0.6517 - val_loss: 0.8995 - val_accuracy: 0.7230\n",
      "Epoch 72/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.0676 - accuracy: 0.6443\n",
      "Epoch 72: val_loss did not improve from 0.88330\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0582 - accuracy: 0.6491 - val_loss: 0.8856 - val_accuracy: 0.7304\n",
      "Epoch 73/100\n",
      "192/219 [=========================>....] - ETA: 0s - loss: 1.0521 - accuracy: 0.6522\n",
      "Epoch 73: val_loss improved from 0.88330 to 0.87673, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0471 - accuracy: 0.6530 - val_loss: 0.8767 - val_accuracy: 0.7287\n",
      "Epoch 74/100\n",
      "193/219 [=========================>....] - ETA: 0s - loss: 1.0122 - accuracy: 0.6702\n",
      "Epoch 74: val_loss did not improve from 0.87673\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0260 - accuracy: 0.6650 - val_loss: 0.8865 - val_accuracy: 0.7304\n",
      "Epoch 75/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.0454 - accuracy: 0.6550\n",
      "Epoch 75: val_loss did not improve from 0.87673\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0456 - accuracy: 0.6548 - val_loss: 0.9069 - val_accuracy: 0.7029\n",
      "Epoch 76/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.0603 - accuracy: 0.6525\n",
      "Epoch 76: val_loss improved from 0.87673 to 0.85527, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0568 - accuracy: 0.6517 - val_loss: 0.8553 - val_accuracy: 0.7493\n",
      "Epoch 77/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 1.0707 - accuracy: 0.6484\n",
      "Epoch 77: val_loss did not improve from 0.85527\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0696 - accuracy: 0.6494 - val_loss: 0.9075 - val_accuracy: 0.7127\n",
      "Epoch 78/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.0493 - accuracy: 0.6529\n",
      "Epoch 78: val_loss did not improve from 0.85527\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0631 - accuracy: 0.6491 - val_loss: 0.9099 - val_accuracy: 0.7333\n",
      "Epoch 79/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0232 - accuracy: 0.6595\n",
      "Epoch 79: val_loss did not improve from 0.85527\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0263 - accuracy: 0.6574 - val_loss: 0.8685 - val_accuracy: 0.7270\n",
      "Epoch 80/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.0192 - accuracy: 0.6678\n",
      "Epoch 80: val_loss did not improve from 0.85527\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0178 - accuracy: 0.6676 - val_loss: 0.8553 - val_accuracy: 0.7459\n",
      "Epoch 81/100\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 1.0392 - accuracy: 0.6612\n",
      "Epoch 81: val_loss did not improve from 0.85527\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0342 - accuracy: 0.6628 - val_loss: 0.8653 - val_accuracy: 0.7367\n",
      "Epoch 82/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 1.0578 - accuracy: 0.6577\n",
      "Epoch 82: val_loss did not improve from 0.85527\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0548 - accuracy: 0.6578 - val_loss: 0.8661 - val_accuracy: 0.7241\n",
      "Epoch 83/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 1.0416 - accuracy: 0.6603\n",
      "Epoch 83: val_loss did not improve from 0.85527\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0427 - accuracy: 0.6580 - val_loss: 0.8657 - val_accuracy: 0.7252\n",
      "Epoch 84/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 1.0154 - accuracy: 0.6672\n",
      "Epoch 84: val_loss did not improve from 0.85527\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0205 - accuracy: 0.6663 - val_loss: 0.8887 - val_accuracy: 0.7155\n",
      "Epoch 85/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0314 - accuracy: 0.6573\n",
      "Epoch 85: val_loss improved from 0.85527 to 0.84496, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0367 - accuracy: 0.6560 - val_loss: 0.8450 - val_accuracy: 0.7413\n",
      "Epoch 86/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 1.0229 - accuracy: 0.6589\n",
      "Epoch 86: val_loss did not improve from 0.84496\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0230 - accuracy: 0.6584 - val_loss: 0.8541 - val_accuracy: 0.7281\n",
      "Epoch 87/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 1.0367 - accuracy: 0.6558\n",
      "Epoch 87: val_loss did not improve from 0.84496\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0397 - accuracy: 0.6568 - val_loss: 0.8613 - val_accuracy: 0.7384\n",
      "Epoch 88/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 1.0340 - accuracy: 0.6583\n",
      "Epoch 88: val_loss did not improve from 0.84496\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0311 - accuracy: 0.6588 - val_loss: 0.8607 - val_accuracy: 0.7327\n",
      "Epoch 89/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 1.0112 - accuracy: 0.6637\n",
      "Epoch 89: val_loss did not improve from 0.84496\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0091 - accuracy: 0.6641 - val_loss: 0.8877 - val_accuracy: 0.7235\n",
      "Epoch 90/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.0195 - accuracy: 0.6629\n",
      "Epoch 90: val_loss improved from 0.84496 to 0.84218, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0174 - accuracy: 0.6634 - val_loss: 0.8422 - val_accuracy: 0.7413\n",
      "Epoch 91/100\n",
      "191/219 [=========================>....] - ETA: 0s - loss: 1.0171 - accuracy: 0.6643\n",
      "Epoch 91: val_loss improved from 0.84218 to 0.83997, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0165 - accuracy: 0.6636 - val_loss: 0.8400 - val_accuracy: 0.7413\n",
      "Epoch 92/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 1.0105 - accuracy: 0.6654\n",
      "Epoch 92: val_loss did not improve from 0.83997\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0115 - accuracy: 0.6656 - val_loss: 0.8490 - val_accuracy: 0.7418\n",
      "Epoch 93/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 1.0106 - accuracy: 0.6658\n",
      "Epoch 93: val_loss improved from 0.83997 to 0.82869, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0100 - accuracy: 0.6681 - val_loss: 0.8287 - val_accuracy: 0.7516\n",
      "Epoch 94/100\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 0.9983 - accuracy: 0.6702\n",
      "Epoch 94: val_loss improved from 0.82869 to 0.81944, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0009 - accuracy: 0.6680 - val_loss: 0.8194 - val_accuracy: 0.7430\n",
      "Epoch 95/100\n",
      "192/219 [=========================>....] - ETA: 0s - loss: 1.0024 - accuracy: 0.6792\n",
      "Epoch 95: val_loss did not improve from 0.81944\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0088 - accuracy: 0.6775 - val_loss: 0.8486 - val_accuracy: 0.7436\n",
      "Epoch 96/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.0172 - accuracy: 0.6622\n",
      "Epoch 96: val_loss improved from 0.81944 to 0.81718, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0172 - accuracy: 0.6624 - val_loss: 0.8172 - val_accuracy: 0.7453\n",
      "Epoch 97/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 0.9978 - accuracy: 0.6744\n",
      "Epoch 97: val_loss did not improve from 0.81718\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.9965 - accuracy: 0.6756 - val_loss: 0.8468 - val_accuracy: 0.7418\n",
      "Epoch 98/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 0.9994 - accuracy: 0.6712\n",
      "Epoch 98: val_loss did not improve from 0.81718\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0030 - accuracy: 0.6716 - val_loss: 0.8281 - val_accuracy: 0.7447\n",
      "Epoch 99/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.0131 - accuracy: 0.6632\n",
      "Epoch 99: val_loss did not improve from 0.81718\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0086 - accuracy: 0.6634 - val_loss: 0.8211 - val_accuracy: 0.7516\n",
      "Epoch 100/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 0.9937 - accuracy: 0.6784\n",
      "Epoch 100: val_loss improved from 0.81718 to 0.80784, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.9932 - accuracy: 0.6777 - val_loss: 0.8078 - val_accuracy: 0.7430\n",
      "Training completed in time:  0:00:49.036095\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7429879903793335\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a0342260c0d89f8598e6c1fc9e59b280635bb4e72447c7d3f2c302ef705beb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
