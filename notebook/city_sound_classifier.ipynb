{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy import signal\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        sample_rate,audio=wav.read(file_name)\n",
    "        #audio, samplerate = sf.read('existing_file.wav')\n",
    "        \n",
    "        # ??\n",
    "        audio = audio.astype(np.float32, order='C') / 32768.00\n",
    "        \n",
    "        # transform to monochannel\n",
    "        try:\n",
    "            d = (audio[:,0] + audio[:,1]) / 2\n",
    "            f = signal.resample(d, 22050)\n",
    "        except:\n",
    "            f = signal.resample(audio, 22050)\n",
    "\n",
    "        #print('samplerate',sample_rate)\n",
    "        #f = signal.resample(d, 22050)\n",
    "        \n",
    "        # ?? args\n",
    "        mfccs = mfcc(f, samplerate =22050, numcep=20,nfilt=26,nfft=1024, appendEnergy=False)\n",
    "        print(mfccs)\n",
    "        print(\"shape\",mfccs.shape)\n",
    "        print('t',np.transpose(mfccs).shape)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        #print(pad_width)\n",
    "        #print('Sample_rate',sample_rate)\n",
    "        #input()\n",
    "        \n",
    "        # ? pq?\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        print(mfccs.shape)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        print(e)\n",
    "        return None\n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = 'C:/Users/lglar/Documents/2021/TCC/SOM/UrbanSound8K/audio/'\n",
    "\n",
    "metadata = pd.read_csv('C:/Users/lglar/Documents/2021/TCC/SOM/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "\n",
    "features =[]\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    #file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    file_name = fulldatasetpath +'fold'+str(row[\"fold\"])+'/'+str(row[\"slice_file_name\"])\n",
    "    #print(file_name)\n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "    #input()\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(featuresdf[featuresdf.feature.isna()]))\n",
    "featuresdf = featuresdf[featuresdf.feature.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf['class'].tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ???\n",
    "num_rows = 99\n",
    "num_columns = 174\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,input_shape=(num_rows,num_columns,num_channels),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "          \n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime\n",
    "\n",
    "#num_epochs = 12\n",
    "#num_batch_size = 128\n",
    "\n",
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "#model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "\n",
    "print (\"History keys:\", (history.history.keys()))\n",
    "# summarise history for training and validation set accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarise history for training and validation set loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    \n",
    "    prediction_feature = extract_features(file_name) \n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test_ = np.argmax(y_test, axis=1)\n",
    "conf = confusion_matrix(y_test_,y_pred )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(conf,le.classes_,le.classes_)\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 12}) # font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(model.history['accuracy'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe: Musica de rua\n",
    "\n",
    "filename = \"C:/Users/lglar/Documents/2021/TCC/SOM/UrbanSound8K/audio/fold2/66996-8-1-0\" \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe: Cachorro\n",
    "\n",
    "filename = \"C:/Users/lglar/Documents/2021/TCC/SOM/UrbanSound8K/audio/fold2/18581-3-1-1.wav\" \n",
    "print_prediction(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('tcc_v3.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "numpy.save('classes_v3.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def save_pyaudio_file():\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 16000\n",
    "    RECORD_SECONDS = 5\n",
    "    WAVE_OUTPUT_FILENAME = \"temp_output.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* recording\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"* done recording\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# Esse é mais simples. mas parece que o pyaudio funciona melhor para rasp? Checar\n",
    "def save_sdaudio_file(samplerate, duration, filename):\n",
    "\n",
    "    print('* init rec')\n",
    "    mydata = sd.rec(int(samplerate * duration), samplerate=samplerate,\n",
    "                    channels=1, blocking=True)\n",
    "    print('* end rec')\n",
    "    sf.write(filename, mydata, samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    temp_filename = 'temp_output.wav'\n",
    "    \n",
    "    save_sdaudio_file(16000, 5, temp_filename)\n",
    "    print_prediction(temp_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* init rec\n",
      "* end rec\n",
      "[[-1.04071069e+02 -2.95273625e+01  6.84270023e-01 ... -1.01828080e+00\n",
      "  -7.50778190e-01 -4.36329208e-01]\n",
      " [-8.07633504e+01 -1.80366615e+01 -3.96753160e+01 ...  2.62862526e+00\n",
      "   2.48843160e+00  1.52358253e+00]\n",
      " [-6.45780466e+01 -1.55241182e+01 -2.41704969e+01 ...  2.74556416e+00\n",
      "   6.76309390e-01  1.28494557e-01]\n",
      " ...\n",
      " [-5.16582586e+01 -1.09377689e+01 -2.38498717e+01 ... -3.97055149e+00\n",
      "  -9.54678201e-02 -6.28385605e-01]\n",
      " [-5.47047074e+01 -1.33142583e+01 -2.89806592e+01 ... -5.46547282e+00\n",
      "  -2.68110052e-01  4.99510138e-01]\n",
      " [-6.18288321e+01 -1.87656816e+01 -3.41657965e+01 ... -5.79436348e+00\n",
      "   2.60326055e+00  3.89550273e-03]]\n",
      "shape (99, 20)\n",
      "t (20, 99)\n",
      "(99, 174)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\felip\\OneDrive\\Documentos\\_Maua\\tcc\\ml_tcc\\notebook\\city_sound_classifier.ipynb Célula: 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     run()\n",
      "\u001b[1;32mc:\\Users\\felip\\OneDrive\\Documentos\\_Maua\\tcc\\ml_tcc\\notebook\\city_sound_classifier.ipynb Célula: 26\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m temp_filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtemp_output.wav\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m save_sdaudio_file(\u001b[39m16000\u001b[39m, \u001b[39m5\u001b[39m, temp_filename)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m print_prediction(temp_filename)\n",
      "\u001b[1;32mc:\\Users\\felip\\OneDrive\\Documentos\\_Maua\\tcc\\ml_tcc\\notebook\\city_sound_classifier.ipynb Célula: 26\u001b[0m in \u001b[0;36mprint_prediction\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m prediction_feature \u001b[39m=\u001b[39m extract_features(file_name) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m prediction_feature \u001b[39m=\u001b[39m prediction_feature\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, num_rows, num_columns, num_channels)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m predicted_vector \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_classes(prediction_feature)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m predicted_class \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39minverse_transform(predicted_vector) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Documentos/_Maua/tcc/ml_tcc/notebook/city_sound_classifier.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe predicted class is:\u001b[39m\u001b[39m\"\u001b[39m, predicted_class[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a0342260c0d89f8598e6c1fc9e59b280635bb4e72447c7d3f2c302ef705beb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
